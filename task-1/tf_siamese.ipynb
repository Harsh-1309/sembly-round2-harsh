{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6055fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4b4979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d1330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout, Input, GRU, dot\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c7dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515e833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d952e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harsh/projects/sembly-round2-harsh\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513bef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"task-1/data/cleaned_data.csv\")\n",
    "y_true=df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6402f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.array(y_true.values.tolist())\n",
    "y_true=y_true.reshape(len(y_true),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bfc9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1=df[\"question1\"]\n",
    "question2=df[\"question2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039af0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808532"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions = list(df['question1']) + list(df['question2'])\n",
    "len(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b11ae03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the story of kohinor  koh i nor  diamond'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b6918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(question):\n",
    "    words = []\n",
    "    #clean the questions of all punctuations\n",
    "    for word in tqdm(question):\n",
    "        clean = re.sub(r\"[^a-z A-Z 0-9]\", \" \", word)\n",
    "        clean = word_tokenize(clean)\n",
    "        words.append([i.lower() for i in clean])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63034c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 808532/808532 [00:57<00:00, 14046.00it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe45d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc46467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(cleaned_words, filters='!\"#$%&*+,-./:;<=>?@[\\]^`{|}~'):\n",
    "    #tokenize the cleaned words in questions upto word level \n",
    "    token = Tokenizer(filters=filters)\n",
    "    token.fit_on_texts(cleaned_words)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de40d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(cleaned_words):\n",
    "    #get the number of words in longest question\n",
    "    return len(max(cleaned_words, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd27e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = create_tokenizer(all_questions)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca6ac3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "    return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69ba3ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x7f8d9d8987c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebd32bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c696bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "    return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ee58051",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ead67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(len(padded_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e42a9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_vectors=padded_doc[:int(len(padded_doc)/2)]\n",
    "question2_vectors=padded_doc[int(len(padded_doc)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "56253a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# np.random.shuffle(question1_vectors)\n",
    "q1_training, q1_test = question1_vectors[:int(len(question1_vectors)*0.8),:], question1_vectors[int(len(question1_vectors)*0.8):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2a3f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# np.random.shuffle(question2_vectors)\n",
    "q2_training, q2_test = question2_vectors[:int(len(question2_vectors)*0.8),:], question2_vectors[int(len(question2_vectors)*0.8):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a63bc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# np.random.shuffle(y_true)\n",
    "y_training, y_test = y_true[:int(len(y_true)*0.8),:], y_true[int(len(y_true)*0.8):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "08ebc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor():\n",
    "    inputs = Input(max_length)\n",
    "    x=inputs\n",
    "    x = Embedding(vocab_size, 128, trainable = False)(x)\n",
    "#     x = LSTM(128,activation=\"relu\")(x)\n",
    "    x = Dense(64, activation = \"relu\")(x)  \n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation = \"relu\")(x)  \n",
    "    x = Dense(16, activation = \"relu\")(x)  \n",
    "#     x= Dense(1)(x)\n",
    "#     x=tf.nn.l2_normalize(x,axis=-1)\n",
    "    outputs=x\n",
    "    outputs = keras.layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a6d9a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 247)]             0         \n",
      "                                                                 \n",
      " embedding_12 (Embedding)    (None, 247, 128)          10616320  \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 247, 64)           8256      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 247, 64)           0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 247, 32)           2080      \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 247, 16)           528       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 247, 1)            17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,627,201\n",
      "Trainable params: 10,881\n",
      "Non-trainable params: 10,616,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=feature_extractor()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "203655ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_q1=Input(max_length)\n",
    "input_q2=Input(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9fe8ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "FE=feature_extractor()\n",
    "q1_layer=FE(input_q1)\n",
    "q2_compare_layer=FE(input_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a466ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = dot([q1_layer, q2_compare_layer], axes=1, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54a15217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "db2c35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1_layer = tf.keras.layers.Lambda(lambda tensors: K.sqrt(K.maximum(K.sum(K.square(tensors[0] - tensors[1]),axis=1,\n",
    "#         keepdims=True),K.epsilon())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f07fa989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1_distance = L1_layer([q1_layer, q2_compare_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ed2977f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Dense(1, activation=\"sigmoid\")(dot_product)\n",
    "model = Model(inputs=[input_q1,input_q2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ba7c80c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)          [(None, 247)]        0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 247)]        0           []                               \n",
      "                                                                                                  \n",
      " model_19 (Functional)          (None, 247, 1)       10627201    ['input_26[0][0]',               \n",
      "                                                                  'input_27[0][0]']               \n",
      "                                                                                                  \n",
      " dot_6 (Dot)                    (None, 1, 1)         0           ['model_19[0][0]',               \n",
      "                                                                  'model_19[1][0]']               \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 1, 1)         2           ['dot_6[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,627,203\n",
      "Trainable params: 10,883\n",
      "Non-trainable params: 10,616,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eb6577cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            min_delta=1e-5,\n",
    "            patience=10,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"task-1/saved_models/tf_model/siamese\",\n",
    "            monitor='val_loss', \n",
    "            mode='min', \n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.2,\n",
    "            patience=4, \n",
    "            min_lr=0.001)\n",
    "    \n",
    "]\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "# loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# acc = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0370d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c4b553f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2017/2022 [============================>.] - ETA: 0s - loss: 0.6625 - accuracy: 0.6232\n",
      "Epoch 1: val_loss improved from inf to 0.65967, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 18s 8ms/step - loss: 0.6625 - accuracy: 0.6232 - val_loss: 0.6597 - val_accuracy: 0.6124 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "2021/2022 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.6307\n",
      "Epoch 2: val_loss improved from 0.65967 to 0.64938, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 16s 8ms/step - loss: 0.6516 - accuracy: 0.6307 - val_loss: 0.6494 - val_accuracy: 0.6327 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "2022/2022 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.6308\n",
      "Epoch 3: val_loss improved from 0.64938 to 0.64610, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 16s 8ms/step - loss: 0.6479 - accuracy: 0.6308 - val_loss: 0.6461 - val_accuracy: 0.6332 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "2021/2022 [============================>.] - ETA: 0s - loss: 0.6446 - accuracy: 0.6319\n",
      "Epoch 4: val_loss did not improve from 0.64610\n",
      "2022/2022 [==============================] - 14s 7ms/step - loss: 0.6446 - accuracy: 0.6319 - val_loss: 0.6485 - val_accuracy: 0.6331 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "2018/2022 [============================>.] - ETA: 0s - loss: 0.6421 - accuracy: 0.6335\n",
      "Epoch 5: val_loss improved from 0.64610 to 0.64241, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 16s 8ms/step - loss: 0.6421 - accuracy: 0.6335 - val_loss: 0.6424 - val_accuracy: 0.6345 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "2020/2022 [============================>.] - ETA: 0s - loss: 0.6398 - accuracy: 0.6359\n",
      "Epoch 6: val_loss did not improve from 0.64241\n",
      "2022/2022 [==============================] - 15s 7ms/step - loss: 0.6399 - accuracy: 0.6359 - val_loss: 0.6424 - val_accuracy: 0.6345 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "2021/2022 [============================>.] - ETA: 0s - loss: 0.6375 - accuracy: 0.6372\n",
      "Epoch 7: val_loss improved from 0.64241 to 0.64039, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 16s 8ms/step - loss: 0.6375 - accuracy: 0.6372 - val_loss: 0.6404 - val_accuracy: 0.6355 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "2022/2022 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.6396\n",
      "Epoch 8: val_loss improved from 0.64039 to 0.63981, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 17s 8ms/step - loss: 0.6356 - accuracy: 0.6396 - val_loss: 0.6398 - val_accuracy: 0.6360 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "2016/2022 [============================>.] - ETA: 0s - loss: 0.6338 - accuracy: 0.6418\n",
      "Epoch 9: val_loss improved from 0.63981 to 0.63780, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6338 - accuracy: 0.6418 - val_loss: 0.6378 - val_accuracy: 0.6372 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "2016/2022 [============================>.] - ETA: 0s - loss: 0.6321 - accuracy: 0.6429\n",
      "Epoch 10: val_loss improved from 0.63780 to 0.63730, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6322 - accuracy: 0.6428 - val_loss: 0.6373 - val_accuracy: 0.6387 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "2019/2022 [============================>.] - ETA: 0s - loss: 0.6305 - accuracy: 0.6457\n",
      "Epoch 11: val_loss improved from 0.63730 to 0.63685, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6304 - accuracy: 0.6457 - val_loss: 0.6369 - val_accuracy: 0.6388 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "2019/2022 [============================>.] - ETA: 0s - loss: 0.6290 - accuracy: 0.6467\n",
      "Epoch 12: val_loss improved from 0.63685 to 0.63645, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6290 - accuracy: 0.6467 - val_loss: 0.6364 - val_accuracy: 0.6393 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "2014/2022 [============================>.] - ETA: 0s - loss: 0.6279 - accuracy: 0.6475\n",
      "Epoch 13: val_loss improved from 0.63645 to 0.63523, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6278 - accuracy: 0.6476 - val_loss: 0.6352 - val_accuracy: 0.6409 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "2022/2022 [==============================] - ETA: 0s - loss: 0.6271 - accuracy: 0.6482\n",
      "Epoch 14: val_loss did not improve from 0.63523\n",
      "2022/2022 [==============================] - 17s 9ms/step - loss: 0.6271 - accuracy: 0.6482 - val_loss: 0.6362 - val_accuracy: 0.6389 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "2021/2022 [============================>.] - ETA: 0s - loss: 0.6263 - accuracy: 0.6495\n",
      "Epoch 15: val_loss improved from 0.63523 to 0.63463, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 19s 9ms/step - loss: 0.6263 - accuracy: 0.6495 - val_loss: 0.6346 - val_accuracy: 0.6417 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "2018/2022 [============================>.] - ETA: 0s - loss: 0.6255 - accuracy: 0.6504\n",
      "Epoch 16: val_loss did not improve from 0.63463\n",
      "2022/2022 [==============================] - 17s 8ms/step - loss: 0.6256 - accuracy: 0.6503 - val_loss: 0.6354 - val_accuracy: 0.6378 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "2015/2022 [============================>.] - ETA: 0s - loss: 0.6246 - accuracy: 0.6518\n",
      "Epoch 17: val_loss improved from 0.63463 to 0.63445, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 19s 9ms/step - loss: 0.6246 - accuracy: 0.6518 - val_loss: 0.6345 - val_accuracy: 0.6411 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "2018/2022 [============================>.] - ETA: 0s - loss: 0.6238 - accuracy: 0.6522\n",
      "Epoch 18: val_loss did not improve from 0.63445\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6238 - accuracy: 0.6522 - val_loss: 0.6354 - val_accuracy: 0.6387 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "2016/2022 [============================>.] - ETA: 0s - loss: 0.6231 - accuracy: 0.6518\n",
      "Epoch 19: val_loss improved from 0.63445 to 0.63366, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 19s 9ms/step - loss: 0.6231 - accuracy: 0.6517 - val_loss: 0.6337 - val_accuracy: 0.6422 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "2022/2022 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.6534\n",
      "Epoch 20: val_loss did not improve from 0.63366\n",
      "2022/2022 [==============================] - 17s 9ms/step - loss: 0.6228 - accuracy: 0.6534 - val_loss: 0.6359 - val_accuracy: 0.6368 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "2019/2022 [============================>.] - ETA: 0s - loss: 0.6221 - accuracy: 0.6534\n",
      "Epoch 21: val_loss did not improve from 0.63366\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6221 - accuracy: 0.6534 - val_loss: 0.6338 - val_accuracy: 0.6425 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "2022/2022 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.6544\n",
      "Epoch 22: val_loss did not improve from 0.63366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 17s 9ms/step - loss: 0.6213 - accuracy: 0.6544 - val_loss: 0.6346 - val_accuracy: 0.6402 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "2019/2022 [============================>.] - ETA: 0s - loss: 0.6211 - accuracy: 0.6540\n",
      "Epoch 23: val_loss improved from 0.63366 to 0.63294, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 20s 10ms/step - loss: 0.6211 - accuracy: 0.6540 - val_loss: 0.6329 - val_accuracy: 0.6430 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "2016/2022 [============================>.] - ETA: 0s - loss: 0.6202 - accuracy: 0.6555\n",
      "Epoch 24: val_loss did not improve from 0.63294\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6202 - accuracy: 0.6555 - val_loss: 0.6348 - val_accuracy: 0.6391 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "2021/2022 [============================>.] - ETA: 0s - loss: 0.6206 - accuracy: 0.6546\n",
      "Epoch 25: val_loss did not improve from 0.63294\n",
      "2022/2022 [==============================] - 17s 9ms/step - loss: 0.6206 - accuracy: 0.6546 - val_loss: 0.6338 - val_accuracy: 0.6402 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "2018/2022 [============================>.] - ETA: 0s - loss: 0.6199 - accuracy: 0.6559\n",
      "Epoch 26: val_loss did not improve from 0.63294\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6200 - accuracy: 0.6559 - val_loss: 0.6332 - val_accuracy: 0.6448 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "2016/2022 [============================>.] - ETA: 0s - loss: 0.6192 - accuracy: 0.6553\n",
      "Epoch 27: val_loss did not improve from 0.63294\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 0.6192 - accuracy: 0.6553 - val_loss: 0.6334 - val_accuracy: 0.6418 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "2016/2022 [============================>.] - ETA: 0s - loss: 0.6190 - accuracy: 0.6564\n",
      "Epoch 28: val_loss improved from 0.63294 to 0.63279, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 20s 10ms/step - loss: 0.6190 - accuracy: 0.6564 - val_loss: 0.6328 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "2018/2022 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.6570\n",
      "Epoch 29: val_loss improved from 0.63279 to 0.63243, saving model to task-1/saved_models/tf_model/siamese\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tf_model/siamese/assets\n",
      "2022/2022 [==============================] - 21s 10ms/step - loss: 0.6188 - accuracy: 0.6570 - val_loss: 0.6324 - val_accuracy: 0.6425 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "2017/2022 [============================>.] - ETA: 0s - loss: 0.6184 - accuracy: 0.6572\n",
      "Epoch 30: val_loss did not improve from 0.63243\n",
      "2022/2022 [==============================] - 17s 9ms/step - loss: 0.6185 - accuracy: 0.6572 - val_loss: 0.6337 - val_accuracy: 0.6400 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([q1_training,q2_training], y_training,\n",
    "                    epochs = 30, batch_size = 128, validation_split=0.2, \n",
    "                    callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3ca739e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2527/2527 [==============================] - 7s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict([q1_test,q2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3532e521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80854, 1, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2f4b0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.round(y_pred).flatten()\n",
    "# y_pred[0]\n",
    "score = classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1052a923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74     50989\n",
      "           1       0.52      0.35      0.42     29865\n",
      "\n",
      "    accuracy                           0.64     80854\n",
      "   macro avg       0.60      0.58      0.58     80854\n",
      "weighted avg       0.62      0.64      0.62     80854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bd1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
