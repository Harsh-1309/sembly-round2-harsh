{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Bidirectional, Embedding, Dropout, Input, GRU\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harsh/projects/sembly-round2-harsh/task-1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harsh/projects/sembly-round2-harsh\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"task-1/data/cleaned_data.csv\")\n",
    "y_true=df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer=pickle.load(open(\"task-1/data/tfidf/tfidf_transformer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1=df[\"question1\"][:10000]\n",
    "question2=df[\"question2\"][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions = list(question1) + list(question2)\n",
    "len(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# analyze = vectorizer.build_analyzer()\n",
    "transformer=vectorizer.fit(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_vectors=transformer.transform(question1)\n",
    "question2_vectors=transformer.transform(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_vectors = question1_vectors.todense()\n",
    "question2_vectors = question2_vectors.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14711)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1_vectors[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 29422)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.hstack((question1_vectors[:],question2_vectors[:]))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(max(x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y_true[:10000],test_size=0.3,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(29422))\n",
    "# model.add(SimpleRNN(8,activation=\"relu\",input_shape=(29422,1,)))\n",
    "# \n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "# model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32,activation=\"relu\",kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_Accuracy',\n",
    "            min_delta=1e-5,\n",
    "            patience=10,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"task-1/saved_models/tfidf/gru\",\n",
    "            monitor='val_loss', \n",
    "            mode='min', \n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.2,\n",
    "            patience=4, \n",
    "            min_lr=0.001)\n",
    "    \n",
    "]\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "# loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# acc = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"Adam\", metrics = [\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.8005 - Accuracy: 0.6318\n",
      "Epoch 1: val_loss improved from inf to 0.63745, saving model to task-1/saved_models/tfidf/gru\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tfidf/gru/assets\n",
      "219/219 [==============================] - 3s 10ms/step - loss: 0.7924 - Accuracy: 0.6350 - val_loss: 0.6375 - val_Accuracy: 0.6843 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.5375 - Accuracy: 0.7606\n",
      "Epoch 2: val_loss improved from 0.63745 to 0.60315, saving model to task-1/saved_models/tfidf/gru\n",
      "INFO:tensorflow:Assets written to: task-1/saved_models/tfidf/gru/assets\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.5375 - Accuracy: 0.7606 - val_loss: 0.6031 - val_Accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.3864 - Accuracy: 0.8555\n",
      "Epoch 3: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.3870 - Accuracy: 0.8549 - val_loss: 0.6523 - val_Accuracy: 0.6930 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.2897 - Accuracy: 0.9014\n",
      "Epoch 4: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.2904 - Accuracy: 0.9003 - val_loss: 0.7002 - val_Accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2313 - Accuracy: 0.9266\n",
      "Epoch 5: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.2311 - Accuracy: 0.9267 - val_loss: 0.7556 - val_Accuracy: 0.6937 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.1909 - Accuracy: 0.9438\n",
      "Epoch 6: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1904 - Accuracy: 0.9444 - val_loss: 0.8051 - val_Accuracy: 0.6927 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.1592 - Accuracy: 0.9576\n",
      "Epoch 7: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1589 - Accuracy: 0.9579 - val_loss: 0.8405 - val_Accuracy: 0.6933 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.1395 - Accuracy: 0.9620\n",
      "Epoch 8: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1399 - Accuracy: 0.9616 - val_loss: 0.8606 - val_Accuracy: 0.6943 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1227 - Accuracy: 0.9690\n",
      "Epoch 9: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1227 - Accuracy: 0.9690 - val_loss: 0.8811 - val_Accuracy: 0.6967 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.1162 - Accuracy: 0.9708\n",
      "Epoch 10: val_loss did not improve from 0.60315\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1167 - Accuracy: 0.9704 - val_loss: 0.9160 - val_Accuracy: 0.6940 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_data= (x_test, y_test), callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
